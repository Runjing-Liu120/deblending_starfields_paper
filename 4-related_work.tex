% \subsection{Connection with variational EM}
% Wake sleep was originally proposed by~\cite{Hinton1995wake_sleep}, and revisited in~\cite{bornschein2014reweighted, le2018revisiting}. \cite{le2018revisiting} proposed wake-sleep as a viable alternative to the reparameterization trick when training discrete-distribution latent variable models. 

% We also note the connection between wake-sleep and variational EM~\cite{Jordan_intro_vi, neal2000varem, Beal2002varem}. For iterations $t = 1, ..., T$, variational EM alternates between two objectives: 
% \begin{align}
%     \text{{\bf E-step: }} & 
%     \eta_{t} = \argmin_\eta \; \mathrm{KL}\big (q_{\eta    }(N, \ell, f |X) \| P_{\phi_{t - 1}}(N, \ell, f | X)\big)
%     \label{eq:e_step}
%     \\
%     \text{{\bf M-step: }} & \phi_{t} = \argmin_{\phi} \; \mathrm{KL}\big (q_{\eta_t}(N, \ell, f |X) \| P_{\phi}(N, \ell, f | X)\big)
%     \label{eq:m_step}
% \end{align}
% The M-step in variational EM and the wake phase in wake-sleep are the same (compare equations~\eqref{eq:wake_kl} and \eqref{eq:m_step}). 
% Variational EM can be viewed as coordinate descent on the KL, with each step alternating between updating $\eta$ and $\phi$. The overall objective is 
% \begin{align}
% (\eta^*, \phi^*) = \argmin_{\phi, \eta} \; \mathrm{KL}\big (q_{\eta}(N, \ell, f |X) \| P_{\phi}(N, \ell, f | X)\big)\label{eq:em_obj}
% \end{align}

% The sleep phase is analogous to the E-step (compare equation~\eqref{eq:sleep_kl} and \eqref{eq:e_step}). 
% The sleep phase objective reverses the arguments of the KL in the E-step so it becomes more amenable to stochastic gradient methods. However, wake-sleep is no longer optimizing a single objective as in equation~\ref{eq:em_obj}. 

% \subsection{Cataloging of stellar fields}
% TODO

\jeff{I don't think we're going to want a dedicated ``Related work'' section. 
It's going to make more sense to discuss related work within the Introduction and Discussion sections.
Dedicated ``related work'' sections probably work best in papers that are so similar to other papers that
a reader will struggle to understand how the new work is different than what others have done.
The work in this paper is pretty clearly novel.
}

In addition to the telescope images, the data releases of SDSS also contain 
a corresponding catalog and estimates of background and PSF. These estimates were obtained using the cataloger PHOTO~\cite{lupton2001sdss}. However, PHOTO was not designed for crowded starfields and timed out when attempting to catalog M2. 

DAOPHOT~\cite{stetson2987daophot} is an algorithmic routine designed for crowded starfields. To detect stars, the observed image is convolved with a Gaussian kernel. The convolved image is scanned for peaks above a given threshold, which are then labeled as stars. In Section~\ref{sec:results}, we compare our method with the catalog reported in \cite{An_2008_m2}, where DAOPHOT was used to catalog M2. 

\cite{Brewer_2013, Portillo_2017, Feder_2019} also employed probabilistic modeling, though inference was done using MCMC. \cite{Portillo_2017, Feder_2019} called their procedure PCAT (Probabilistic CATaloging). \cite{Feder_2019} is the extension 
of \cite{Portillo_2017} to multiband images. Our generative model is identical to PCAT, except PCAT used an exponential prior on the number of stars instead of Poisson. 

In \cite{Brewer_2013}, a broken power law prior was used for the flux. 
Further hyper-priors were placed on the parameters of the broken power-law, and the parameters of the broken power law were treated as latent variables. In our case, this would be analogous to placing a hyper-prior on $\alpha$ in \eqref{eq:flux_prior}. Alternatively, though not explored in this work, we can treat $\alpha$ as a model parameter to optimize in the wake phase. The same principle applies to the Poisson prior parameter, $\mu$. 

Finally, PCAT used the SDSS estimates for the PSF and background obtained by PHOTO.
As will be shown in Section~\ref{sec:results_model_params}, the SDSS estimates for the PSF and background can be improved for a better model fit (recall that PHOTO timed out 
on the image of M2). $\cite{Brewer_2013}$ treated PSF parameters as latent variables in their generative model and placed priors on them. In contrast, we treated PSF parameters as model parameters to be estimated in the wake phase. 

% in the most recent work \cite{Feder_2019}, a runtime of 30min was reported to catalog a $100 \times 100$ subimage of M2. In the sequel, we compare the catalog produced from their MCMC procedure against the catalog produced by our variational posterior. We show that our method is several orders of magnitude faster at inference time. 