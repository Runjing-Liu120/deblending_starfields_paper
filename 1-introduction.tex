Astronomical images record the arrival of photons from distant light sources. 
These images are one of the few sources of information about the universe beyond our solar system.
Typically, astronomical catalogs are constructed from this image data.
Catalogs label light sources as stars, galaxies, or other objects; 
they also list the physical characteristics of light sources such as flux, color, and morphology. 
These catalogs are the starting point for many downstream analyses.
For example, Bayestar used a catalog of stellar fluxes and colors to construct the 3D distribution of interstellar dust~\cite{Green_2019_argonaut}. 
Catalogs of galaxy morphologies have been used to validate theoretical models of dark matter and dark energy~\cite{Eisenstein_2005_darkmatter}. 

Catalog construction is straightforward when light sources are well separated. Each light source produces a single peak intensity on the image, and characteristics of the light source such as flux can be estimated by analyzing photon counts in the surrounding pixels. 
However, in images crowded with light sources, peak intensities may be the result of the combined light from multiple sources.
Light source separation, or {\itshape deblending}, is the task of characterizing each individual light source from an overlapping peak intensity on an image. 
A key challenge in deblending is inferring whether a peak intensity is in fact blended, that is, whether the peak is comprised of a single bright source or multiple dimmer sources. 

% In such settings, a key step in catalog construction is light source separation, or {\itshape deblending}, the process of 
% Deblending first involves distinguishing whether a peak intensity corresponds to a single light source or multiple light sources. 
% If multiple sources are detected, the properties of each light source are then inferred. 

Deblending is challenging for several reasons.
First, it is an unsupervised problem without ground truth labeled data. 
Secondly, it is a problem with a sample size of one: there is only one night sky, which is imaged many times, and the collected survey images capture overlapping regions of it.
Third, for blended fields, the properties of light sources are especially ambiguous as pixel intensities may be attributed to multiple sources. Therefore, providing calibrated uncertainty quantification is as important as making accurate predictions.
Finally, the scale of the data is immense by any standard. The upcoming Large Synoptic Survey Telescope (LSST) survey, scheduled to begin data collection in 2022, is expected to produce 50 petabytes of astronomical images over its lifetime~\cite{LSST_about}.

As more powerful telescopes are developed and their ability to detect more distant light sources improves, the density of light sources in the images they capture will only increase. 
For instance, \cite{Bosch_2017_LSST} estimates that in LSST, 68\% of the light sources will be blended. Therefore, developing a method to produce reliable catalogs, even in cases of significant light source blending, would advance astronomical research. 

% We focus our attention on applications where all sources are well-modeled as points without spatial extent.
% We use the M2 globular cluster, a region of the sky densely populated by stars, 
% as a test bed for our method. 
% Other applications of point-source models include DECam~\cite{Schlafly_2018_DECam}, which imaged the center of our own Milky Way and WISE~\cite{Wright_2010_WISESurvey}, whose telescope resolution did not allow for differentiation between stars and galaxies.

\bigbreak

\noindent{\textbf{From algorithmic software pipelines to probabilistic cataloging}}

Traditionally, most cataloging has been performed using algorithmic software pipelines.
These pipelines involve the following stages: locating the brightest peaks, estimating fluxes, and subtracting the estimated light source.
These stages may be performed iteratively.
These pipelines do not normally produce statistically calibrated error estimates that propagate 
the uncertainty accumulating in each step of the pipeline. 
Therefore, most of these pipelines do not work well for highly blended light sources where ambiguity exists in identifying sources and estimating their characteristics.
For example, PHOTO~\cite{lupton2001sdss}, the default cataloging pipeline used by the Sloan Digital Sky Survey (SDSS), fails to 
produce a catalog for certain crowded starfields known as globular clusters~\cite{Portillo_2017}. 

In contrast, {\itshape probabilistic} cataloging posits a statistical model consisting of a likelihood for the observed image and a prior distribution over possible catalogs~\cite{Portillo_2017, Brewer_2013, Feder_2019}. 
Instead of deriving a single catalog, probabilistic cataloging produces a posterior distribution over the set of all possible catalogs. 
In other words, each sample from the posterior is a catalog. 
Uncertainties are quantified by the posterior distribution. 
For example, in an image with an ambiguously blended bright peak, some catalogs sampled from the posterior would contain multiple dim light sources while others would contain one bright source. 
The relative density the posterior distribution places on one explanation over another represents the statistical confidence in that explanation. 
Moreover, a distribution over the set of all catalogs induces a distribution on any estimate derived from a catalog. Therefore, calibrated uncertainties can be propagated to downstream analyses.  

Previous work on probabilistic cataloging employed Markov chain Monte Carlo (MCMC) to sample from the posterior distribution.
The MCMC procedure in~\cite{Portillo_2017, Feder_2019}
was named PCAT, short for ``Probabilistic CATaloging."\footnote{
We use ``probabilistic cataloging'' to refer to any method that produces a posterior over possible catalogs, whereas ``PCAT" refers specifically to the MCMC procedure in~\cite{Portillo_2017, Feder_2019}. }
Because the posterior is defined over the set of all catalogs and the number of sources in a catalog is unknown and random, 
the latent variable space is transdimensional. PCAT
used reversible jump MCMC (RJ-MCMC) ~\cite{Green95reversiblejump} to sample transdimensional catalogs. In RJ-MCMC, auxiliary variables are added to encode the ``birth" of new sources 
or the ``death" of existing sources in the Markov chain.

The computational cost of MCMC for this model is prohibitive for large-scale astronomical surveys. 
Early implementations of PCAT required a day to process a $100\times 100$ pixel image of the M2 globular cluster imaged by SDSS~\cite{Portillo_2017}. 
More recent implementations running inexact MCMC brought the runtime down to 30  minutes~\cite{Feder_2019}.  
In any case, a $100\times 100$ image covers only a $0.66 \times 0.66$ arcminute patch of the sky.
For comparison, in one night, SDSS scans a region on the order of $100 \times 1000$ arcminutes. 
Extrapolating the 30 minute runtime, PCAT would take about three months to process the same amount of data.

As an alternative to MCMC, \cite{regier2019_celeste} produced an approximate posterior using variational inference.
Variational inference (VI) considers a constrained family of distributions and employs numerical optimization to find the distribution in the family closest
in KL divergence to the exact posterior~\cite{Blei_2017_vi_review,Jordan_intro_vi, Wainwrite_graph_models_vi}. 
With a sufficiently constrained family of distributions, the VI optimization problem can be orders of magnitude faster than MCMC. 

However, \cite{regier2019_celeste} is limited in that the number of light sources in a given image is treated as known and fixed; the number of light sources in the catalog had to be set by a preprocessing routine. 
This simplification was made in order to have a tractable objective for numerical optimization. 

\bigbreak

\noindent{\textbf{Our contribution}}

\nopagebreak[4]

We propose {\itshape StarNet}, a deblending approach employing several recent VI innovations~\cite{zhang2019advances,le2020revisiting}.
Unlike \cite{regier2019_celeste}, our VI approach is able to handle arbitrary probabilistic models, including a transdimensional model with an unknown number of sources. Section~\ref{sec:gen_model} introduces the statistical model, which is similar to the model used in PCAT. Like PCAT, StarNet considers applications where all sources are well modeled as points without spatial extent, with starfields being a primary example. 

Secondly, unlike~\cite{regier2019_celeste}, 
we employ {\itshape amortization}, which enables StarNet to scale inference to large astronomical surveys. 
In amortized variational inference, a neural network is fit to map input images to an approximate posterior.
After a one-time cost to fit the neural network, inference 
on new images requires just a single forward pass.
Rapid inference is available without the need to re-run MCMC or numerically optimize for each new image. 
For StarNet, the forward pass on 
a $100 \times 100$ pixel image takes $0.2$ seconds (cf.~30 minutes for inference using PCAT).
Section~\ref{sec:var_inference} details the variational distribution and neural network architecture in StarNet. 

Finally, and critically, StarNet is fit using the wake-sleep algorithm~\cite{Hinton1995wake_sleep}, which does not target the same KL divergence traditionally used in  variational inference. In traditional variational inference, the approximate posterior is fit to minimize the ``reverse" KL between the approximate posterior $q$ and the true posterior $p$, defined as the $q$-weighted average difference between $\log q$ and $\log p$. 
Wake-sleep instead fits the approximate posterior using the ``forward" KL divergence, which weights the difference between $\log q$ and $\log p$ by $p$.
The forward KL is minimized using stochastic gradient descent (SGD). 
Procedurally, in this SGD routine, catalogs are sampled from the prior distribution along with corresponding images from the likelihood model. 
The neural network is trained to map the sampled images to distributions that place probability mass on their corresponding catalogs. Section~\ref{sec:wake_sleep} details the wake-sleep procedure. 

In this application, optimizing the forward KL produces more reliable approximate posteriors than optimizing the traditional reverse KL (Section \ref{sec:elbo_sleep_compare}). 
In particular, by taking advantage of complete data---the sampled images and their corresponding catalogs---wake-sleep avoids shallow local minima where the approximate posterior returned by the neural network is far from the true posterior in terms of KL divergence. 

The wake-sleep algorithm has been used in previous research to train deep generative models~\cite{Hinton1995wake_sleep, bornschein2014reweighted, le2020revisiting}.
However, to the best of our knowledge, this is the first application of wake-sleep for scientific purposes. 
Specifically, we use wake-sleep for inference to find a latent space that is interpretable, as it is the set of all possible astronomical catalogs.

We validated StarNet on the M2 globular cluster, a region of the sky densely populated by stars. StarNet was more accurate than the MCMC-based cataloger PCAT and traditional cataloging approaches while running $100,000$ times faster than the former (Section~\ref{sec:results_on_m2}).
While the MCMC posterior approximation converges to the exact posterior asymptotically, over finite horizons an MCMC sampler may not mix well. The sleep-phase objective from the Wake-Sleep algorithm allows StarNet to circumvent many of the challenges of nonconvex optimization.
(Section~\ref{sec:discussion}).

% However, in addition to greater speed, amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 



% In particular, the usual stochastic gradients of the reverse KL 
% were too high-variance to be used in in our application; 
% in contrast, low-variance stochastic gradients of the forward KL are computationally cheap to compute. 


% low-variance stochastic gradients of the forward KL are much cheaper to compute than stochastic gradients of the reverse KL. Moreover, we hypothesize that amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 






% The neural network outputs are not simply ``labels" for the input image 






% In traditional variational inference, the divergence between 
% the variational posterior $q$ and the true posterior $p$ is 
% measured by the ``reverse" KL divergence, defined as the 
% $q$-weighted average difference between $\log q$ and $\log p$. In other words, the reverse KL divergence
% is defined by an expectation with integrating distribution $q$. 

% In simple models, for example when $p$ and $q$ are appropriate classes of exponential families, 
% the expectation over $q$ can be written explicitly as a function of the parameters of $q$. Therefore, the minimizer of the KL can be solved either in closed form or by employing deterministic optimization~\cite{Blei_2017_vi_review}. 

% In our setting of amortized variational inference, the parameters of $q$ are neural network weights. When analytic expectations are unavailable, as in our case, 
% sampling methods have been employed in conjunction with modern auto-differentiation tools to compute stochastic gradients. Optimization is done with stochastic gradient descent. Examples include black-box variational inference (BBVI)~\cite{ranganath2013black} 
% and automatic-differentiation variational inference (ADVI)~\cite{kucukelbir2016automatic}. The latter 
% is closely related to the reparameterization trick \cite{kingma2013autoencoding, rezende2014stochastic} proposed to train deep generative models using the KL objective. 
% These approaches all sample latent variables from $q$ and produce an unbiased estimate 
% for the gradient of the KL. 

% However, the reparameterization trick does not apply when any latent variables are discrete, in our case, the number of stars. The REINFORCE estimator~\cite{Williams1992reinforce}, which BBVI adapts, produces an unbiased stochastic gradient for both continuous and discrete latent variables. However, the REINFORCE estimator often suffers from high variance in practice, and so the resulting stochastic optimization is slow. 

% The key difficulty is that the objective function is 
% an expectation with integrating distribution on $q$, the  distribution to be optimized. To avoid this issue, the {\itshape wake-sleep} algorithm considers the ``forward" KL divergence, defined as the
% $p$-weighted average difference between $\log p$ and $\log q$;  in other words, the expectation is taken over $p$. To make the forward KL divergence tractable, a second average is taken over possible data. In other words, the neural network is trained so that {\itshape on average over possible input images $x$}, the 
% variational distribution returned by the neural network is close to the true posterior in forward KL divergence. 

% Low-variance stochastic gradients are easy to compute using the wake-sleep algorithm, and we show that these low-variance gradients result in faster optimization than using the REINFORCE gradient estimator. 
% However, in addition to greater speed, amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 



% In simple models, for example when both $p$ and $q$ are related exponential families, the expectation can be written explicitly as a function of the parameters of $q$~\cite{Blei_2017_vi_review}. Therefore, the KL can be minimized either in closed form, or by using deterministic optimization. However, in our case, the parameters of $q$ are neural network weights. In this setting, ~\cite{rezende2014stochastic,kingma2013autoencoding} propose 
% stochastic optimization, where an unbiased gradient of the KL divergence is computed from samples of $q$. 





% One limitation of neural networks is the large amount of data needed for training.
% In astronomy, knowledge of the physical system  often give rise to reasonably realistic simulators for data. For example, simulators were used in \cite{Lanusse_2017_cmudeeplens} trained neural networks to detect Einstein rings, 
% a rare object found in astronomical surveys and used to study dark matter; the neural network in \cite{Hezaveh_2017_nn_lensing_nature} also returned
% morphological parameters for each Einstein ring. 
% In both cases, because the training data was generated from a simulator, the ground truth labels (ring exists or not; the ring morphology) are known. The network is trained in a supervised fashion. Using simulated data is especially useful because the network can be trained on essentially unlimited data -- the bottleneck is the limit on computational resources, not the availability of training data. 

% In our work, we also make use of simulated data to train our neural network. However, we introduce the simulated data in the context of a statistical model. We do so using the wake-sleep algorithm~\cite{Hinton1995wake_sleep}. 
% The neural network outputs are not simply ``labels" for the input image; rather, we are able to interpret the output as specifying an approximate Bayesian posterior in the context of a well-defined statistical model. 

% In summary, we leverage the predictive power and computational efficiency of neural networks to do 
% inference in the framework of a statistical model. 
% We also employ simulated data in our training procedure in a statistically principled way. In Section~\ref{sec:results}, we compare the catalog obtained from our variational posterior with the catalog derived from MCMC; we also compare with traditional cataloging approaches.  

% detect Einstein rings; \cite{Hezaveh_2017_nn_lensing_nature} used
% neural networks to infer morphological characteristics of the Einstein rings; 
% in the context of deblending, 
% \cite{Reiman_2019_gans_deblend} used 
% GANS to separate two overlapping galaxies. 

% Several factors contribute to the success of neural networks. Firstly, neural networks are computationally efficient; multiple images can be easily evaluated in parallel on a GPU.
% Secondly, a well-trained neural network is able to generalize beyond the data on which is was trained. This combined with computational efficiency is extremely beneficial for sky surveys: after training a neural network on a subset of the survey, the remaining images in the survey can be evaluated quickly in batches using only forward-passes through the network. 

% In this paper, we combine the flexibility of neural networks with a formal statistical model. This enables the neural network output to be interpreted in a statistically principled way: the output of our neural network will be a distribution that approximates the Bayesian posterior.

% Secondly, we train the neural network using {\itshape wake-sleep} training. This allows our neural network to be trained using unlimited simulated data. Using simulated data to train neural networks is common practice is astronomy (see for example~\cite{Lanusse_2017_cmudeeplens, huang2019finding}). However, we also make the connection with a formal statistical model 
% and introduce the simulated data in a principled way. TODO: yikes ... this paragraph is terrible and needs work. 

% In Section~\ref{sec:gen_model} we introduce 
% the generative model. Section~\ref{sec:var_inference} details the variational distribution and discuss training of the neural network. Section~\ref{sec:related_work} makes connections with previous cataloging software. In Section~\ref{sec:results}, we compare 
% our variational inference procedure with MCMC as well as more traditional cataloging software pipelines. Section 6 concludes. 

