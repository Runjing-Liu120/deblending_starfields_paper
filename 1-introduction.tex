Astronomical surveys employ telescopes to scan the sky and record the arrival of photons from distant light sources. 
The collected telescope images are the primary source of information about the universe beyond our solar system. 
Typically, catalogs are inferred from the data.
Catalogs label light sources as stars, galaxies, or other objects; 
they also list their physical characteristics such as flux, color, and morphology. 
These catalogs are the starting point for many downstream analyses.
For example, the Argonaut map used a catalog of stellar fluxes and colors to construct the 3D distribution of interstellar dust~\cite{Green_2019_argonaut}. 
Catalogs of galaxy morphologies have been used to validate theoretical models of dark matter and dark energy~\cite{Eisenstein_2005_darkmatter}. 

Catalog construction is straightforward when light sources are well-separated: after identifying the peak intensities in an image, characteristics such as flux can be estimated by analyzing photon counts in surrounding pixels. 
However, in images crowded with light sources, peak intensities may correspond to multiple sources.
In such settings, a key step in catalog construction is light source separation, or {\itshape deblending}. 
Deblending first involves distinguishing whether a peak intensity corresponds to a single light source or multiple light sources. 
If multiple sources are detected, the properties of each light source are then characterized. 

Deblending is challenging for several reasons.
First, it is an unsupervised problem with a sample size of one: the availability of labeled data with known ground truth is limited, and there is only one night sky, which is imaged many times.
Second, in blended fields, characterizing light sources becomes ambiguous as pixel intensities may be attributed to multiple sources. Therefore providing calibrated uncertainty quantification is as important as making accurate predictions.
Third, the scale of the data is immense by any standard. The upcoming Large Synoptic Survey Telescope (LSST) survey, scheduled to begin data collection in 2022, is expected to produce 50 petabytes of astronomical images over its lifetime~\cite{LSST_about}.

As telescopes improve and peer deeper into space, the density of light sources will only increase. 
For instance, \cite{Bosch_2017_LSST} estimates that in LSST, 68\% of the light sources will be blended. Therefore, developing a method to produce reliable catalogs even in cases of significant source blending will be required for advancing astronomical research. 

\bigbreak

\noindent{\textbf{From algorithmic software pipelines to probabilistic cataloging}}

Traditionally, most cataloging has been done using algorithmic software pipelines, with steps involving locating the the brightest peaks, estimating fluxes, subtracting out the estimated light source, and repeating.
These pipelines usually do not produce statistically calibrated error estimates that propagate 
uncertainties accumulating in each step of the pipeline. 
Therefore, most of these pipelines do not work well for highly blended light sources where identifying sources and estimating their characteristics are ambiguous. 
The default SDSS cataloging pipeline (PHOTO~\cite{lupton2001sdss}), for example, fails to 
produce a catalog on crowded starfields known as globular clusters~\cite{Portillo_2017}. 

Alternatively, {\itshape probabilistic} cataloging posits a statistical model consisting of a likelihood for the observed image and a prior distribution over possible catalogs~\cite{Brewer_2013, Portillo_2017, Feder_2019}. 
Instead of deriving a single catalog, probabilistic cataloging produces a posterior distribution over the set of all possible catalogs. 
In other words, each sample from the posterior is a catalog. 
Uncertainties are quantified by the posterior distribution. 
For example, in an image with an ambiguously blended bright peak, some posterior samples would indicate multiple dim light sources while others would indicate one bright source. 
The relative weight the posterior distribution places on one explanation over another represents the statistical confidence in that explanation. 
Moreover, a distribution over the set of all catalogs induces a distribution on any estimate derived from a catalog. Therefore, calibrated uncertainties can be propagated to downstream analyses.  

Previous work on probabilistic cataloging employed Markov chain Monte Carlo (MCMC) to sample from the posterior distribution.
The MCMC procedure in~\cite{Portillo_2017, Feder_2019}
was named PCAT, short for ``Probabilistic CATaloging."\footnote{
We use ``probabilistic cataloging'' to refer to any method that produces a posterior over possible catalogs, whereas ``PCAT" refers specifically the the MCMC procedure in~\cite{Portillo_2017, Feder_2019}. }
Because the posterior is defined over the set of all catalogs and the number of sources in a catalog is unknown and random, 
the latent variable space is transdimensional. PCAT employed
employed reversible jump MCMC~\cite{Green95reversiblejump} to sample transdimensional catalogs. In RJ-MCMC, auxiliary variables are added to encode the ``birth" of new sources 
or the ``death" of existing sources in the Markov chain.

In this complex model, the computational cost of MCMC is prohibitive for large-scale astronomical surveys. 
PCAT required 30 minutes to process a $100\times 100$ pixel image of the M2 globular cluster imaged by the Sloan Digial Sky Survey (SDSS). 
The image covers roughly a $0.3\times0.3$ arcsecond patch of the sky.
For comparison, in one night SDSS scans a region of size on the order of $10 \times 1000$ arcminutes. 
Extrapolating the reported 30min runtime, PCAT would take about two months to process one night's data collection.

As an alternative to MCMC, \cite{regier2019_celeste} produced an approximate posterior using variational inference.
Variational inference (VI) considers a constrained family of distributions and employs numerical optimization to find the distribution in the family closest
in KL divergence to the exact posterior~\cite{Blei_2017_vi_review,Jordan_intro_vi, Wainwrite_graph_models_vi}. 
With a sufficiently constrained family of distributions, the VI optimization problem can be orders of magnitude faster than MCMC. 

However \cite{regier2019_celeste} is limited in that the number of light sources in a given image is treated as known and fixed in their statistical model. They avoid the transdimensionality of the latent space altogether. The number of light sources in the catalog thus had to be set by a preprocessing routine. 
Other modeling decisions, such as choices of conjugate priors, were also made in order to have a tractable objective for numerical optimization. 

\bigbreak

\noindent{\textbf{Our contribution}}

\nopagebreak[4]

We propose {\itshape StarNet}, an approach employing {\itshape amortized} variational inference with neural networks to produce probabilistic catalogs. 
Unlike \cite{regier2019_celeste}, our VI approach is able to handle arbitrary probabilistic models, including a transdimensional model with an unknown number of sources. Section~\ref{sec:gen_model} introduces the statistical model, which is similar to the model used in PCAT. Like PCAT, StarNet considers applications where all sources are well-modeled as points without spatial extent, with starfields being a primary example. 

The amortizated approach enables StarNet to scale inference to large astronomical surveys.
In amortized variational inference, a neural network is fit to map input images to an approximate posterior.
After a one-time cost to fit the neural network, inference 
on new images requires just a single forward pass.
Rapid inference is available without re-running MCMC or numerical optimization for each new image. 
For StarNet, the forward pass on 
a $100 \times 100$ pixel image takes $\approx 0.2$ seconds (cf.~30 minutes for inference using MCMC). Moreover, neural networks can efficiently evaluate batches of images in parallel on a GPU. 
Section~\ref{sec:var_inference} details the variational distribution and neural network architecture in StarNet. 

Finally, StarNet is fit using the wake-sleep algorithm~\cite{Hinton1995wake_sleep}, which does not target the same KL divergence traditionally used in  variational inference. In traditional variational inference, the approximate posterior is fit to minimize the ``reverse" KL between the approximate posterior $q$ and the true posterior $p$, defined as the $q$-weighted average difference between $\log q$ and $\log p$. 
Wake-sleep instead fits the approximate posterior using the ``forward" KL divergence, which weights the difference between $\log q$ and $\log p$ by $p$.
Procedurally, to minimize the forward KL, catalogs are sampled from the prior distribution along with corresponding images from the likelihood model. 
The neural network is trained to map the sampled images to distributions that place probability mass on their corresponding catalogs. Section~\ref{sec:wake_sleep} details the wake-sleep procedure. 

We find that in our application, optimizing the forward KL produces more reliable approximate posteriors than optimizing the traditional reverse KL (Section \ref{sec:estep_sleep_compare}). 
In particular, by taking advantage of complete data -- the sampled images and their corresponding catalogs -- our method is able to avoid shallow local minima where the approximate posterior returned by the neural network is far from the true posterior in KL divergence. 

The wake-sleep algorithm has been used in prior work to train deep generative models~\cite{Hinton1995wake_sleep, bornschein2014reweighted, le2018revisiting}.
However, to the best of our knowledge, this is the first application of wake-sleep for scientific purposes. 
Specifically, we use wake-sleep for inference in a setting where the latent space is interpretable: the latent space is the set of all possible astronomical catalogs. 

Section~\ref{sec:deblending_test} demonstrates the ability of StarNet to deblend two overlapping stars. 
Section~\ref{sec:results_on_m2} evaluates StarNet on the M2 globular cluster, a region of the sky densely populated by stars. The results from StarNet are compared against the MCMC-based cataloger PCAT as well as 
with traditional cataloging approaches. Section~\ref{sec:discussion} concludes. 

% However, in addition to greater speed, amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 



% In particular, the usual stochastic gradients of the reverse KL 
% were too high-variance to be used in in our application; 
% in contrast, low-variance stochastic gradients of the forward KL are computationally cheap to compute. 


% low-variance stochastic gradients of the forward KL are much cheaper to compute than stochastic gradients of the reverse KL. Moreover, we hypothesize that amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 






% The neural network outputs are not simply ``labels" for the input image 






% In traditional variational inference, the divergence between 
% the variational posterior $q$ and the true posterior $p$ is 
% measured by the ``reverse" KL divergence, defined as the 
% $q$-weighted average difference between $\log q$ and $\log p$. In other words, the reverse KL divergence
% is defined by an expectation with integrating distribution $q$. 

% In simple models, for example when $p$ and $q$ are appropriate classes of exponential families, 
% the expectation over $q$ can be written explicitly as a function of the parameters of $q$. Therefore, the minimizer of the KL can be solved either in closed form or by employing deterministic optimization~\cite{Blei_2017_vi_review}. 

% In our setting of amortized variational inference, the parameters of $q$ are neural network weights. When analytic expectations are unavailable, as in our case, 
% sampling methods have been employed in conjunction with modern auto-differentiation tools to compute stochastic gradients. Optimization is done with stochastic gradient descent. Examples include black-box variational inference (BBVI)~\cite{ranganath2013black} 
% and automatic-differentiation variational inference (ADVI)~\cite{kucukelbir2016automatic}. The latter 
% is closely related to the reparameterization trick \cite{kingma2013autoencoding, rezende2014stochastic} proposed to train deep generative models using the KL objective. 
% These approaches all sample latent variables from $q$ and produce an unbiased estimate 
% for the gradient of the KL. 

% However, the reparameterization trick does not apply when any latent variables are discrete, in our case, the number of stars. The REINFORCE estimator~\cite{Williams1992reinforce}, which BBVI adapts, produces an unbiased stochastic gradient for both continuous and discrete latent variables. However, the REINFORCE estimator often suffers from high variance in practice, and so the resulting stochastic optimization is slow. 

% The key difficulty is that the the objective function is 
% an expectation with integrating distribution on $q$, the  distribution to be optimized. To avoid this issue, the {\itshape wake-sleep} algorithm considers the ``forward" KL divergence, defined as the
% $p$-weighted average difference between $\log p$ and $\log q$;  in other words, the expectation is taken over $p$. To make the forward KL divergence tractable, a second average is taken over possible data. In other words, the neural network is trained so that {\itshape on average over possible input images $x$}, the 
% variational distribution returned by the neural network is close to the true posterior in forward KL divergence. 

% Low-variance stochastic gradients are easy to compute using the wake-sleep algorithm, and we show that these low-variance gradients result in faster optimization than using the REINFORCE gradient estimator. 
% However, in addition to greater speed, amortized inference may be better at nonconvex optimization: by learning a policy from many examples we learn a policy for avoiding shallow local minima. 



% In simple models, for example when both $p$ and $q$ are related exponential families, the expectation can be written explicitly as a function of the parameters of $q$~\cite{Blei_2017_vi_review}. Therefore, the KL can be minimized either in closed form, or by using deterministic optimization. However, in our case, the parameters of $q$ are neural network weights. In this setting, ~\cite{rezende2014stochastic,kingma2013autoencoding} propose 
% stochastic optimization, where an unbiased gradient of the KL divergence is computed from samples of $q$. 





% One limitation of neural networks is the large amount of data needed for training.
% In astronomy, knowledge of the physical system  often give rise to reasonably realistic simulators for data. For example, simulators were used in \cite{Lanusse_2017_cmudeeplens} trained neural networks to detect Einstein rings, 
% a rare object found in astronomical surveys and used to study dark matter; the neural network in \cite{Hezaveh_2017_nn_lensing_nature} also returned
% morphological parameters for each Einstein ring. 
% In both cases, because the training data was generated from a simulator, the ground truth labels (ring exists or not; the ring morphology) are known. The network is trained in a supervised fashion. Using simulated data is especially useful because the network can be trained on essentially unlimited data -- the bottleneck is the limit on computational resources, not the availability of training data. 

% In our work, we also make use of simulated data to train our neural network. However, we introduce the simulated data in the context of a statistical model. We do so using the wake-sleep algorithm~\cite{Hinton1995wake_sleep}. 
% The neural network outputs are not simply ``labels" for the input image; rather, we are able to interpret the output as specifying an approximate Bayesian posterior in the context of a well-defined statistical model. 

% In summary, we leverage the predictive power and computational efficiency of neural networks to do 
% inference in the framework of a statistical model. 
% We also employ simulated data in our training procedure in a statistically principled way. In Section~\ref{sec:results}, we compare the catalog obtained from our variational posterior with the catalog derived from MCMC; we also compare with traditional cataloging approaches.  

% detect Einstein rings; \cite{Hezaveh_2017_nn_lensing_nature} used
% neural networks to infer morphological characteristics of the Einstein rings; 
% in the context of deblending, 
% \cite{Reiman_2019_gans_deblend} used 
% GANS to separate two overlapping galaxies. 

% Several factors contribute to the success of neural networks. Firstly, neural networks are computationally efficient; multiple images can be easily evaluated in parallel on a GPU.
% Secondly, a well-trained neural network is able to generalize beyond the data on which is was trained. This combined with computational efficiency is extremely beneficial for sky surveys: after training a neural network on a subset of the survey, the remaining images in the survey can be evaluated quickly in batches using only forward-passes through the network. 

% In this paper, we combine the flexibility of neural networks with a formal statistical model. This enables the neural network output to be interpreted in a statistically principled way: the output of our neural network will be a distribution that approximates the Bayesian posterior.

% Secondly, we train the neural network using {\itshape wake-sleep} training. This allows our neural network to be trained using unlimited simulated data. Using simulated data to train neural networks is common practice is astronomy (see for example~\cite{Lanusse_2017_cmudeeplens, huang2019finding}). However, we also make the connection with a formal statistical model 
% and introduce the simulated data in a principled way. TODO: yikes ... this paragraph is terrible and needs work. 

% In Section~\ref{sec:gen_model} we introduce 
% the generative model. Section~\ref{sec:var_inference} details the variational distribution and discuss training of the neural network. Section~\ref{sec:related_work} makes connections with previous cataloging software. In Section~\ref{sec:results}, we compare 
% our variational inference procedure with MCMC as well as more traditional cataloging software pipelines. Section 6 concludes. 

